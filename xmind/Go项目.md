# Go项目

**介绍一下Go项目**

这是一个基于Go语言开发的在线聊天系统，采用**RESTful API**风格的前后端分离项目，核心功能包括单聊、群聊、多种消息类型发送、离线消息处理、以及好友和群聊管理功能。

在技术选型上，我使用了**Gin框架**来构建HTTP服务，用**Gorm框架**操作MySQL进行数据存储。为了实时通信，我使用**WebSocket**建立长连接，并使用**protobuf**来序列化消息以优化性能。为了应对高并发下大量消息，引入了**Kafka**消息队列来异步处理消息，实现了业务逻辑与消息转发的解耦，显著提升了系统的稳定性和吞吐量。



**消息如何传输以及存储的整个流程**？

1. 消息发送与接收（实时传输层）

- **客户端发送**：客户端通过 WebSocket 连接发送消息，消息格式采用 Protocol Buffer 序列化（定义在pkg/protocol/message.proto），包含发送者 ID、接收者 ID、内容、消息类型等元数据。
- **服务器接收**：WebSocket 连接的`Read`协程（internal/server/client.go）监听消息，首先判断是否为心跳包（`type=heatbeat`），若是则直接返回 PONG 响应；否则将消息转发至服务器的`Broadcast`通道。

2. 消息路由与分发（业务逻辑层）

- **消息解析**：服务器从`Broadcast`通道读取消息后，通过`proto.Unmarshal`解析为`Message`结构体，区分单聊（`messageType=1`）和群聊（`messageType=2`）。
- 精准投递：
  - 单聊消息：通过`sendUserMessage`方法查找接收者的 WebSocket 连接（存储在`Server.Clients`映射表），直接将消息写入其`Send`通道，由`Write`协程发送至客户端。
  - 群聊消息：通过`sendGroupMessage`方法获取群内所有成员 ID，遍历成员列表并向在线成员的连接推送消息（过滤发送者自身）。

3. 消息队列处理（异步扩展层）

- 当系统配置 Kafka 作为消息队列时（configs/configs.toml中`channelType=kafka`），消息会通过internal/kafka/producer.go的`Send`方法写入指定 Kafka 主题。
- 消费者通过`ConsumerMsg`函数（internal/kafka/consumer.go）监听队列，收到消息后重新放入`Broadcast`通道进行分发，实现分布式部署下的消息同步。

4. 消息持久化存储（数据持久层）

- **存储触发**：在消息分发的同时，调用`saveMessage`方法（internal/server/server.go）进行持久化，支持文本、图片、文件等多种类型。
- 特殊处理：
  - 图片 / 文件消息：先解析 Base64 编码或二进制数据，保存至本地文件系统，再将文件 URL 存入数据库。
  - 文本消息：直接提取内容进行存储。
- **数据库写入**：通过`MessageService.SaveMessage`（internal/service/message_service.go）将消息记录写入 MySQL 的`messages`表，包含发送者 ID、接收者 ID、内容、类型、时间戳等字段，同时建立索引优化查询性能。

5. 历史消息查询

- 客户端通过 RESTful API（api/message_controller.go的`GetMessage`接口）查询历史消息，服务端根据消息类型（单聊 / 群聊）执行不同 SQL 查询：
  - 单聊：查询双方互发的消息（`from_user_id`和`to_user_id`双向匹配）。
  - 群聊：查询指定群组 ID 下的所有消息（`message_type=2`）。
- 查询结果封装为`MessageResponse`结构体，包含用户名、头像等扩展信息后返回给客户端。

# Gin

**Gin框架里中间件的使用**

中间件是Gin框架的核心特性之一，它本质上是一个函数，可以在HTTP请求到达具体路由处理函数之前或之后被执行。我通过`Use()`方法将中间件注册到路由上。

1.**CORS跨域中间件：** 因为项目是前后端分离的，前端和后端很可能不在同一个域名下，浏览器会因同源策略阻止请求。使用`cors.Default()`中间件后，它会在响应头中自动添加必要的跨域字段（如`Access-Control-Allow-Origin`），轻松解决了跨域问题。

2.**Recovery中间件：** 它用于捕获任何在HTTP处理过程中可能发生的`panic`（运行时异常）。如果没有它，一旦某个请求处理发生`panic`，整个Web服务进程就会崩溃。Recovery中间件能捕获这个`panic`，记录错误日志，并返回一个500错误响应，从而保证单个请求的错误不会影响整个服务的稳定性。



# WebSocket

**100个在线用户，只有3-4在聊天，如何管理这100websocket连接的**？

1. **连接建立与注册机制**
   当用户发起 WebSocket 连接时（通过`router/socket.go`的`RunSocket`函数），系统会为每个用户创建独立的`Client`实例，包含 WebSocket 连接对象、用户标识和消息发送通道。客户端会通过`Server.Register`通道完成注册，服务器将其存入`Clients`映射表中统一管理，确保每个在线用户的连接状态可追踪。
2. **轻量级读写分离**
   每个客户端连接会异步启动`Read`和`Write`两个 goroutine（`server/client.go`）：
   - `Read`协程负责监听客户端消息，仅在有消息时进行处理（如解析心跳包或转发业务消息），无消息时处于阻塞等待状态，避免资源空耗。
   - `Write`协程通过`Send`通道接收待发送消息，仅在有消息时执行 IO 操作，空闲时不占用 CPU。
3. **消息分发的按需处理**
   对于仅 3-4 人聊天的低活跃场景，系统通过`Server.Broadcast`通道实现消息路由：
   - 非活跃用户的连接虽保持注册状态，但因无消息交互，其`Send`通道为空，`Write`协程处于休眠状态。
   - 活跃用户的消息会根据目标类型（单聊 / 群聊）精准转发（`server/server.go`的`sendUserMessage`和`sendGroupMessage`），避免对所有连接进行无差别广播，减少无效 IO。
4. **资源占用控制**
   - 采用 goroutine 的轻量级并发模型，即使存在 100 个连接，空闲连接的协程也仅占用极少内存（约 2KB / 协程），不会造成资源浪费。
   - 通过`sync.Mutex`保护`Clients`映射表，在处理注册 / 注销和消息分发时确保线程安全，同时避免锁竞争对性能的影响。
5. **心跳检测与连接清理**
   客户端会定期发送心跳包，服务器在`Read`协程中处理心跳并返回响应（`HEAT_BEAT`类型消息），若检测到连接异常（如`ReadMessage`报错），会触发`Ungister`流程，及时关闭无效连接并释放资源，防止僵尸连接占用内存。



**Websocket通信的实现**

在实现上，我首先使用Gin框架初始化了一个HTTP server，然后再通过Upgrade方法将特定的HTTP连接升级为Websocket长连接。每个连接成功后，会创建单独的Goroutine负责监听和读写消息。

为了管理所有在线连接，我设计了一个全局client客户端管理器，采用了全局的map结构存储用户id与client的映射，来实现注册、注销和查找所有在线用户的客户端连接。当收到某个客户端的消息时，服务器会根据消息的类型，比如说单聊还是群聊，以及目标id，从管理器中找到对应的客户端连接，通过websocket将其转发出去。



**Websocket的优缺点**

**优点**

1. **全双工实时通信**
   WebSocket 建立连接后，客户端与服务器可双向持续通信，无需像 HTTP 那样频繁建立连接。例如在项目中，用户发送消息后（client.go 的 `Read` 方法），服务器能立即通过 `Send` 通道推送至接收方，实现毫秒级消息送达，这对即时通讯场景至关重要。
2. **减少通信开销**
   相比 HTTP 轮询（反复发送请求），WebSocket 仅在握手阶段使用 HTTP，后续通信无需重复携带头部信息。在 100 个在线用户的场景中，这种特性显著降低了带宽占用和服务器处理压力（通过 `Server.Clients` 映射表高效管理长连接）。
3. **原生支持二进制传输**
   项目中使用 protobuf 序列化消息（message.proto），WebSocket 可直接传输二进制数据，比 JSON 等文本格式更高效。例如图片、文件等消息（`contentType=3`）通过二进制传输，减少序列化开销。
4. **适合高并发长连接场景**
   基于 Go 语言的 goroutine 轻量级特性，每个 WebSocket 连接对应独立的 `Read` 和 `Write` 协程（client.go），即使大量空闲连接也仅占用少量资源，符合 IM 系统高并发需求。

**缺点**

1. **连接维持成本较高**
   长连接需要服务器持续维护状态（如 `Server.Clients` 映射表），若连接管理不当（如未及时清理僵尸连接），可能导致资源泄漏。项目中通过心跳检测（`HEAT_BEAT` 类型消息）和 `Ungister` 机制缓解此问题，但仍需额外开发成本。
2. **兼容性与中间件限制**
   部分老旧代理服务器或防火墙可能不支持 WebSocket 协议，需要通过 `CheckOrigin: func(r *http.Request) bool { return true }`（socket.go）关闭跨域检查以兼容，但可能引入安全风险。
3. **缺乏内置重连机制**
   网络波动可能导致连接中断，需客户端额外实现重连逻辑。项目中若客户端断线，服务器会通过 `Ungister` 移除连接，但重新连接需客户端主动发起，增加了前后端协调成本。
4. **消息可靠性需额外保障**
   WebSocket 本身不保证消息有序性和不丢失，项目中通过引入 Kafka 消息队列（`kafka/consumer.go` 和 producer.go）实现消息异步处理和重试，弥补了这一缺陷，但增加了系统复杂度。



# Protobuf

**protobuf作用**

出于**性能和数据压缩**的考虑，相比json和xml这写文本格式，protobuf是二进制的，序列化后体积小，在网络传输中速度更快，带宽消耗更低。



**protobuf使用**



# MySQL

**有哪些表**？



**消息有哪些数据**？



**Gorm的软删除**

一个典型的实践是在群组表中使用了软删除（Soft Delete）。通常的删除是硬删除，即执行`DELETE`语句直接从数据库中物理删除记录。但在业务上，我希望保留历史数据以备查询。

Gorm内置支持了软删除。我只需要在群组模型的结构体中嵌入一个`gorm.DeletedAt`字段。当调用`Delete`方法时，Gorm并不会真正删除数据，而是自动将该记录的这个字段更新为当前时间（相当于一个删除标记）。后续的正常查询操作，Gorm会自动过滤掉已被‘软删除’的记录。



# Kafka

**Kafka的作用**

引入Kafka主要是为了解决**系统耦合**和**流量削峰**两个核心问题。

在没有Kafka之前，当用户发送一条消息时，WebSocket服务需要同步地执行查询数据库、处理业务逻辑、最终转发消息这一整套流程。如果在高峰期，瞬时消息量巨大，同步处理可能会阻塞整个服务，导致响应变慢甚至服务崩溃。

引入Kafka后，架构就解耦了。当WebSocket服务收到消息后，它并不立即处理，而是立即将其作为一个Producer**异步地写入Kafka的某个Topic**中就立即返回，告诉用户‘消息已发送’。这样WebSocket层的处理速度非常快。

然后，会有另一个或多个独立的Consumer服务来消费Kafka中的消息，它们负责执行那些耗时的操作，如持久化到数据库、真正地投递消息等。即使消息流量突然激增，也只会堆积在Kafka里，而不会冲垮实时通信服务。Kafka保证了消息的可靠性和顺序性，等流量高峰过去，Consumer会逐步消费掉堆积的消息，从而极大地提高了整个系统的稳定性和容错能力。

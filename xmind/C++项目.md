**介绍一下Go项目**

这是一个基于Go语言开发的在线聊天系统，采用**RESTful API**风格的前后端分离项目，核心功能包括单聊、群聊、多种消息类型发送、离线消息处理、以及好友和群聊管理功能。

在技术选型上，我使用了**Gin框架**来构建HTTP服务，用**Gorm框架**操作MySQL进行数据存储。为了实时通信，我使用**WebSocket**建立长连接，并使用**protobuf**来序列化消息以优化性能。为了应对高并发下大量消息，引入了**Kafka**消息队列来异步处理消息，实现了业务逻辑与消息转发的解耦，显著提升了系统的稳定性和吞吐量。



**消息如何传输以及存储的整个流程**？



**Gin框架里中间件的使用**

中间件是Gin框架的核心特性之一，它本质上是一个函数，可以在HTTP请求到达具体路由处理函数之前或之后被执行。我通过`Use()`方法将中间件注册到路由上。

1.**CORS跨域中间件：** 因为项目是前后端分离的，前端和后端很可能不在同一个域名下，浏览器会因同源策略阻止请求。使用`cors.Default()`中间件后，它会在响应头中自动添加必要的跨域字段（如`Access-Control-Allow-Origin`），轻松解决了跨域问题。

2.**Recovery中间件：** 它用于捕获任何在HTTP处理过程中可能发生的`panic`（运行时异常）。如果没有它，一旦某个请求处理发生`panic`，整个Web服务进程就会崩溃。Recovery中间件能捕获这个`panic`，记录错误日志，并返回一个500错误响应，从而保证单个请求的错误不会影响整个服务的稳定性。



**100个在线用户，只有3-4在聊天，如何管理这100websocket连接的**？



**Websocket通信的实现**

在实现上，我首先使用Gin框架初始化了一个HTTP server，然后再通过Upgrade方法将特定的HTTP连接升级为Websocket长连接。每个连接成功后，会创建单独的Goroutine负责监听和读写消息。

为了管理所有在线连接，我设计了一个全局client客户端管理器，采用了全局的map结构存储用户id与client的映射，来实现注册、注销和查找所有在线用户的客户端连接。当收到某个客户端的消息时，服务器会根据消息的类型，比如说单聊还是群聊，以及目标id，从管理器中找到对应的客户端连接，通过websocket将其转发出去。



**Websocket的优缺点**



**protobuf作用**

出于**性能和数据压缩**的考虑，相比json和xml这写文本格式，protobuf是二进制的，序列化后体积小，在网络传输中速度更快，带宽消耗更低。



**protobuf使用**



**有哪些表**？



**消息有哪些数据**？



**Gorm的软删除**

一个典型的实践是在群组表中使用了软删除（Soft Delete）。通常的删除是硬删除，即执行`DELETE`语句直接从数据库中物理删除记录。但在业务上，我希望保留历史数据以备查询。

Gorm内置支持了软删除。我只需要在群组模型的结构体中嵌入一个`gorm.DeletedAt`字段。当调用`Delete`方法时，Gorm并不会真正删除数据，而是自动将该记录的这个字段更新为当前时间（相当于一个删除标记）。后续的正常查询操作，Gorm会自动过滤掉已被‘软删除’的记录。



**Kafka的作用**

引入Kafka主要是为了解决**系统耦合**和**流量削峰**两个核心问题。

在没有Kafka之前，当用户发送一条消息时，WebSocket服务需要同步地执行查询数据库、处理业务逻辑、最终转发消息这一整套流程。如果在高峰期，瞬时消息量巨大，同步处理可能会阻塞整个服务，导致响应变慢甚至服务崩溃。

引入Kafka后，架构就解耦了。当WebSocket服务收到消息后，它并不立即处理，而是立即将其作为一个Producer**异步地写入Kafka的某个Topic**中就立即返回，告诉用户‘消息已发送’。这样WebSocket层的处理速度非常快。

然后，会有另一个或多个独立的Consumer服务来消费Kafka中的消息，它们负责执行那些耗时的操作，如持久化到数据库、真正地投递消息等。即使消息流量突然激增，也只会堆积在Kafka里，而不会冲垮实时通信服务。Kafka保证了消息的可靠性和顺序性，等流量高峰过去，Consumer会逐步消费掉堆积的消息，从而极大地提高了整个系统的稳定性和容错能力。


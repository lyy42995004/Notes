# 引入Kafka的原因

1. **实现消息异步处理**

即时通讯系统中，消息的收发是非常频繁的操作。如果采用同步方式处理消息，可能会导致服务器在处理大量消息时出现阻塞，影响系统的响应速度和吞吐量。引入 Kafka 作为消息队列，可以实现消息的异步处理。当客户端发送消息时，服务器将消息发送到 Kafka 的指定主题中，然后继续处理其他请求，而不是等待消息处理完成。通过这种方式，消息的生产和消费是异步进行的，不会阻塞服务器的主线程。

2. **解耦消息的生产者和消费者**

在即时通讯系统中，消息的生产者（如客户端发送消息）和消费者（如服务器处理消息）之间的耦合度应该尽可能低，这样可以提高系统的灵活性和可维护性。Kafka 作为消息队列，可以作为生产者和消费者之间的中间层，将两者解耦。生产者只需要将消息发送到 Kafka 的指定主题中，而不需要关心消息是如何被消费的；消费者只需要从 Kafka 的指定主题中消费消息，而不需要关心消息是由谁生产的。

生产者和消费者通过 Kafka 进行通信，彼此之间没有直接的依赖关系，这样可以方便地对生产者和消费者进行独立的开发、测试和维护。

3. **消息持久化和可靠性**

Kafka 可以将消息持久化到磁盘上，确保消息不会丢失。即使在系统出现故障或重启的情况下，Kafka 仍然可以保证消息的可靠性。在即时通讯系统中，消息的可靠性是非常重要的，因为用户发送的消息必须被准确地传递给接收方。

Kafka 通过分区和副本机制来保证消息的可靠性。消息被分割成多个分区，每个分区可以有多个副本，分布在不同的 Kafka 节点上。当某个节点出现故障时，其他副本可以继续提供服务，确保消息的正常处理。

4. **流量削峰填谷**

在即时通讯系统中，消息的流量可能会出现高峰和低谷。例如，在某些特定的时间段，如节假日或活动期间，用户发送消息的数量会大幅增加，导致服务器的负载急剧上升。引入 Kafka 可以起到流量削峰填谷的作用。当消息流量高峰时，Kafka 可以缓存大量的消息，避免服务器因为处理不过来而崩溃；当消息流量低谷时，服务器可以从 Kafka 中取出缓存的消息进行处理，保持系统的稳定运行。

![image.png](https://s2.loli.net/2025/06/07/49xUdehrJzXPFpS.png)

# `main.go`

```go
func main() {
    defer log.Sync() // 记录日志

    log.Info("start chat server...")

    if  mct := config.GetConfig().MsgChannelType; mct.ChannelType == constant.KAFKA {
        kafka.InitProducer(mct.KafkaTopic, mct.KafkaHosts)
        kafka.InitConsumer(mct.KafkaHosts)
        go kafka.ConsumerMsg(server.ConsumerKafkaMsg)
    }

    newRouter := router.NewRouter()

    go server.MyServer.Start()

    s := &http.Server{
        Addr:           ":8080",
        Handler:        newRouter,
        ReadTimeout:    10 * time.Second,
        WriteTimeout:   10 * time.Second,
        MaxHeaderBytes: 1 << 20,
    }
    err := s.ListenAndServe()
    if err != nil {
        log.Error("server start error", log.Err(err))
    }
}
```

在`main`函数中根据配置判断是否使用 Kafka 作为消息队列。

- `if mct := config.GetConfig().MsgChannelType; mct.ChannelType == constant.KAFKA`：通过读取配置文件中的

  `MsgChannelType`，判断是否使用 Kafka。如果是，则执行以下操作：

  - `kafka.InitProducer(mct.KafkaTopic, mct.KafkaHosts)`：调用`kafka`包中的`InitProducer`函数，初始化 Kafka 生产者，指定 Kafka 的主题和地址。
  - `kafka.InitConsumer(mct.KafkaHosts)`：调用`kafka`包中的`InitConsumer`函数，初始化 Kafka 消费者，指定 Kafka 的地址。
  - `go kafka.ConsumerMsg(server.ConsumerKafkaMsg)`：启动一个新的协程，调用`kafka`包中的`ConsumerMsg`函数，开始消费 Kafka 消息，并将消费到的消息传递给`server.ConsumerKafkaMsg`函数进行处理。

# `producer.go`

- `InitProducer`函数：初始化 Kafka 生产者，接收 Kafka 主题和地址作为参数。创建 Kafka 客户端和异步生产者，并设置生产者的压缩方式为 GZIP。
- `Send`函数：将字节数据发送到 Kafka 指定的主题中。
- `Close`函数：关闭 Kafka 生产者。

```go
var producer sarama.AsyncProducer
var topic string = "default_message"

func InitProducer(topicInput, hosts string) {
    topic = topicInput
    config := sarama.NewConfig()
    config.Producer.Compression = sarama.CompressionGZIP

    client, err := sarama.NewClient(strings.Split(hosts, ","), config)
    if err != nil {
        log.Error("init kafka client error", log.Err(err))
    }

    producer, err = sarama.NewAsyncProducerFromClient(client)
    if nil != err {
        log.Error("init kafka async client error", log.Err(err));
    }
}

func Send(data []byte) {
    be := sarama.ByteEncoder(data)
    producer.Input() <- &sarama.ProducerMessage{Topic: topic, Key: nil, Value: be}
}

func Close() {
    if producer != nil {
        producer.Close()
    }
}
```

# `consumer.go`

- `InitConsumer`函数：初始化 Kafka 消费者，接收 Kafka 地址作为参数。创建 Kafka 客户端和消费者。
- `ConsumerMsg`函数：从 Kafka 指定的主题和分区中消费消息，并将消费到的消息传递给回调函数`cb`进行处理。
- `CloseConsumer`函数：关闭 Kafka 消费者。

```go
var consumer sarama.Consumer

type ConsumerCallBack func(data []byte)

func InitConsumer(hosts string) {
    config := sarama.NewConfig()
    client, err := sarama.NewClient(strings.Split(hosts, "."), config)
    if err != nil {
        log.Error("init kafka consumer error", log.Err(err))
    }

    consumer, err = sarama.NewConsumerFromClient(client)
    if err != nil {
        log.Error("init kafka consumer error", log.Err(err))
    }
}

// 消费消息
func ConsumerMsg(cb ConsumerCallBack) {
    partitionConsumer, err := consumer.ConsumePartition(topic, 0, sarama.OffsetNewest)
    if err != nil {
        log.Error("ConsumePartition error", log.Err(err))
    }

    defer partitionConsumer.Close()
    for {
        msg := <-partitionConsumer.Messages()
        if cb != nil {
            cb(msg.Value)
        }
    }
}

func CloseConsumer() {
    if nil != consumer {
        consumer.Close()
    }
}
```

# `server.go`

当 Kafka 消费者消费到消息后，会调用该函数，将消息放入服务器的广播通道`MyServer.Broadcast`中，以便服务器进行统一处理。

```go
// 消费kafka里面的消息, 直接放入go channel中统一进行消费
func ConsumerKafkaMsg(data []byte) {
    MyServer.Broadcast <- data
}
```

>  代码地址：[IM-Go](https://github.com/lyy42995004/IM-Go)
